{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ba213b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T22:08:55.336939Z",
     "iopub.status.busy": "2024-04-12T22:08:55.336461Z",
     "iopub.status.idle": "2024-04-12T22:08:56.919592Z",
     "shell.execute_reply": "2024-04-12T22:08:56.917736Z"
    },
    "papermill": {
     "duration": 1.605848,
     "end_time": "2024-04-12T22:08:56.921857",
     "exception": true,
     "start_time": "2024-04-12T22:08:55.316009",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dataprep'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataprep\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclean\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataprep'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dataprep.clean import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from optuna import create_study, visualization\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "from optuna.samplers import RandomSampler\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import machine_learning_pipeline as mlp\n",
    "import exploratory_data_analysis as eda\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae1013",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f67a1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Loading train and test dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b227de3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_ab.csv')\n",
    "test_df = pd.read_csv('test_ab.csv')\n",
    "\n",
    "# cleaning the headers\n",
    "train_df = clean_headers(train_df)\n",
    "# confirming the id is unique for each row and setting it \n",
    "# as the index\n",
    "assert train_df.id.nunique() == len(train_df)\n",
    "train_df = train_df.set_index('id')\n",
    "\n",
    "test_df = clean_headers(test_df)\n",
    "assert test_df.id.nunique() == len(test_df)\n",
    "test_df = test_df.set_index('id')\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c9e8e8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Handling the Target/Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333791c1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# assigning a column of the dataframe as the tarfet\n",
    "target = 'rings'\n",
    "# defining the type of our target: 'continuous', 'binary' or 'multiclass'\n",
    "target_type = 'continuous'\n",
    "\n",
    "# checking that the target_type is a valid one\n",
    "assert target_type in ['continuous', 'binary', 'multiclass']\n",
    "\n",
    "# encoding the target if binary or multi-class type is chosen\n",
    "if target_type != 'continuous':\n",
    "    le = LabelEncoder()\n",
    "    train_df[target] = le.fit_transform(train_df[target].tolist())\n",
    "    print('Target Encoding:')\n",
    "    for i, clss in enumerate(list(le.classes_)): print(target + ' ' + clss + ' -> ' + target + ' ' + str(i)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9993e043",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Splitting features into numerical and categorical types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd172874",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating a dataframe that lets us know the data types of each one of our \n",
    "# features\n",
    "data_types = pd.DataFrame(train_df.dtypes, columns=['feature_type'])\n",
    "data_types['unique_values'] = train_df.nunique()\n",
    "data_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed41a356",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Although all the columns are numeric, the small number of diffetent values for some columns suggests that the they could be interpreted as categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2961cd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting a threshold to determine categorical columns versus numerical\n",
    "cat_threshold = 10\n",
    "numerical_features, categorical_features = eda.split_features(df=train_df, target_col=target, categorical_threshold=cat_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55abf353",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86eddef",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Pairplot\n",
    "These graphs help us visualize the relationships between our numerical features and the target. For numerical targets the last row of the pairplot corresponds to the target; for categorical targets, the target can be seen as the marker color in each graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78041834",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eda.pairplot(df=train_df,\n",
    "             numerical_features=numerical_features,\n",
    "             target_type=target_type,\n",
    "             target_col=target,\n",
    "             sample=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f0e9fc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Numerical Features Distribution Comparison\n",
    "The graphs below are useful to identify any major differences between our train and test sets that can impact our models. It also shows the general distribution of each of the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e45f33",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eda.train_test_distribution_plots(train_df,\n",
    "                                  test_df,\n",
    "                                  numerical_features,\n",
    "                                  sample=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ccf51",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Categorical Features Distribution Comparison\n",
    "The graphs below are useful to identify any major differences between our train and test sets that can impact our models. It also shows the general distribution of each of the cateorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d403c4a7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eda.train_test_categorical_piecharts(train_df,\n",
    "                                     test_df,\n",
    "                                     categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8b6e72",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e81452",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eda.correlation_plot(train_df[numerical_features + [target]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6bea71",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Model Training with Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b964e441",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Declaring variables needed for optimization step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c728c03",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# splitting the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df.drop(target, axis=1), \n",
    "                                                    train_df[target], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62994669",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# During the model fitting step, the optuna optimizer will include the algorithm \n",
    "# as one of the  hyperparameters of the model. It will try to find the one that \n",
    "# performs the best for our problem.\n",
    "\n",
    "if target_type == 'continuous':    \n",
    "    optimization_objective = 'regression'\n",
    "    # available algorithms for regression tasks. \n",
    "    algorithms = [\n",
    "                    # 'linear', \n",
    "                    # 'ridge',\n",
    "                    # 'histgb',                     \n",
    "                    # 'extratrees', \n",
    "                    'lgb',\n",
    "                    # 'xgb', \n",
    "                    # 'catboost'\n",
    "                ] \n",
    "    \n",
    "    # scoring for cross-validation\n",
    "    optimization_scoring = 'r2'\n",
    "\n",
    "elif target_type == 'binary':\n",
    "    optimization_objective = 'classification'\n",
    "    # available algorithms for binary classification tasks\n",
    "    algorithms = [\n",
    "                    # 'histgb',                     \n",
    "                    # 'extratrees', \n",
    "                    'lgb',\n",
    "                    # 'xgb', \n",
    "                    # 'catboost'\n",
    "                ]\n",
    "    # scoring for cross-validation\n",
    "    optimization_scoring = 'roc_auc'\n",
    "\n",
    "elif target_type == 'multiclass':\n",
    "    optimization_objective = 'multiclass'\n",
    "    # available algorithms for multiclass classification tasks\n",
    "    algorithms = [\n",
    "                    # 'histgb',                     \n",
    "                    'lgb',\n",
    "                ]\n",
    "    # scoring for cross-validation\n",
    "    optimization_scoring = 'neg_log_loss'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ae9ea4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354819f0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# declaring our optuna study\n",
    "factor = 2\n",
    "# the pruner parameter helps make the optimization much faster as it will prune\n",
    "# any iterations that don't look promising right from the start\n",
    "study = create_study(study_name='optimization', \n",
    "                     direction='maximize',\n",
    "                     pruner=SuccessiveHalvingPruner(reduction_factor=factor),\n",
    "                     sampler=RandomSampler(seed=0))\n",
    "\n",
    "\n",
    "# custom function to fit the model using smart hyperparameter search with optuna. This \n",
    "# parameter search is not restricted to the algorithm's hyperparameters. The algorithm\n",
    "# itself is part of the parameters to be optimized. Data preprocessing decisions are \n",
    "# also included here, such as the scaling approach for numerical features, the encoding \n",
    "# technique for categorical variables, as well as feature selection.\n",
    "study.optimize(lambda trial: mlp.objective(trial, \n",
    "                                           X_train, \n",
    "                                           y_train, \n",
    "                                           objective=optimization_objective,\n",
    "                                           algorithms=algorithms,\n",
    "                                           cv_scoring=optimization_scoring,\n",
    "                                           numerical_columns=numerical_features, \n",
    "                                           categorical_columns=categorical_features,\n",
    "                                           base=factor, \n",
    "                                           n_rungs=4), \n",
    "               n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d68b58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T06:17:52.631622Z",
     "iopub.status.busy": "2023-12-19T06:17:52.631111Z",
     "iopub.status.idle": "2023-12-19T06:17:52.637642Z",
     "shell.execute_reply": "2023-12-19T06:17:52.636283Z",
     "shell.execute_reply.started": "2023-12-19T06:17:52.631575Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saving the models best parameters and trial and printing its best score\n",
    "best_model_params = study.best_params\n",
    "best_trial = study.best_trial\n",
    "# printing the score of the best model\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd867f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Optuna trials visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05647a3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T06:17:56.861596Z",
     "iopub.status.busy": "2023-12-19T06:17:56.861069Z",
     "iopub.status.idle": "2023-12-19T06:17:57.589966Z",
     "shell.execute_reply": "2023-12-19T06:17:57.589043Z",
     "shell.execute_reply.started": "2023-12-19T06:17:56.861561Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a369e29c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T06:17:57.685488Z",
     "iopub.status.busy": "2023-12-19T06:17:57.685091Z",
     "iopub.status.idle": "2023-12-19T06:17:58.115549Z",
     "shell.execute_reply": "2023-12-19T06:17:58.114218Z",
     "shell.execute_reply.started": "2023-12-19T06:17:57.685456Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualization.plot_param_importances(study, target_name=\"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c933bc5b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Instantiating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc787fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T06:17:52.640508Z",
     "iopub.status.busy": "2023-12-19T06:17:52.639253Z",
     "iopub.status.idle": "2023-12-19T06:17:56.858322Z",
     "shell.execute_reply": "2023-12-19T06:17:56.856561Z",
     "shell.execute_reply.started": "2023-12-19T06:17:52.640461Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calling the best trial and instantiating the model\n",
    "model = mlp.instantiate_model(best_trial, \n",
    "                              numerical_features, \n",
    "                              categorical_features, \n",
    "                              optimization_objective, \n",
    "                              algorithms)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a72c672",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# printing score on the test set\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8b8f9e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Model Explainability with SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d9706e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Fitting the model on preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8222783",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d186a2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Applying preprocessing steps to our dataset\n",
    "To be able to compute the shap values we need the preprocessed dataset and the chosen model. We'll use the best_model_params dictionary to retrieve them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23c036",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T06:17:58.117404Z",
     "iopub.status.busy": "2023-12-19T06:17:58.117004Z",
     "iopub.status.idle": "2023-12-19T06:18:02.433558Z",
     "shell.execute_reply": "2023-12-19T06:18:02.432512Z",
     "shell.execute_reply.started": "2023-12-19T06:17:58.117372Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesRegressor, HistGradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from category_encoders import OrdinalEncoder, OneHotEncoder, WOEEncoder, TargetEncoder, CatBoostEncoder, SumEncoder, BinaryEncoder, HelmertEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "# numerical_features_used = [col for col in numerical_features if best_model_params[col]]\n",
    "numerical_features_used = numerical_features\n",
    "# categorical_features_used = [col for col in categorical_features if best_model_params[col]]\n",
    "categorical_features_used = categorical_features\n",
    "\n",
    "X_train_preprocessed = X_train[numerical_features_used + categorical_features_used]\n",
    "X_test_preprocessed = X_test[numerical_features_used + categorical_features_used]\n",
    "\n",
    "valid_scaler_params = ['with_centering', 'with_scaling']\n",
    "# Filter out non-preprocessing hyperparameters\n",
    "preprocessing_params = {k: v for k, v in best_model_params.items() if k in valid_scaler_params}\n",
    "final_scaler = RobustScaler(**preprocessing_params)\n",
    "\n",
    "encoder_strategy = best_model_params['categorical_encoder']\n",
    "if encoder_strategy == 'ordinal':\n",
    "    encoder = OrdinalEncoder()\n",
    "elif encoder_strategy == 'onehot':\n",
    "    encoder = OneHotEncoder()\n",
    "elif encoder_strategy == 'binary':\n",
    "    encoder = BinaryEncoder()\n",
    "elif encoder_strategy == 'helmert':\n",
    "    encoder = HelmertEncoder()\n",
    "elif encoder_strategy == 'sum':\n",
    "    encoder = SumEncoder()\n",
    "elif encoder_strategy == 'target':\n",
    "    encoder = TargetEncoder()\n",
    "elif encoder_strategy == 'woe':\n",
    "    encoder = WOEEncoder()\n",
    "elif encoder_strategy == 'catboost':\n",
    "    encoder = CatBoostEncoder()\n",
    "else:\n",
    "    encoder = ''\n",
    "\n",
    "final_processor = ColumnTransformer([\n",
    "    ('scaler', final_scaler, numerical_features_used),\n",
    "    ('encoder', encoder, categorical_features_used)\n",
    "  ])\n",
    "\n",
    "final_model_params = {k: v for k, v in best_model_params.items() if k not in (valid_scaler_params+['categorical_encoder'])}\n",
    "del final_model_params['algorithm']\n",
    "# for col in X_train.columns.to_list():\n",
    "#     del final_model_params[col]\n",
    "# final_model_params['objective'] = 'multiclass'\n",
    "# final_model = HistGradientBoostingRegressor(**final_model_params)\n",
    "final_model = LGBMRegressor(**final_model_params)\n",
    "# final_model = LinearRegression(**final_model_params)\n",
    "\n",
    "X_train_preprocessed = final_processor.fit_transform(X_train_preprocessed, y_train)\n",
    "X_train_preprocessed = pd.DataFrame(X_train_preprocessed, columns=numerical_features + categorical_features, index=X_train.index)\n",
    "\n",
    "X_test_preprocessed = final_processor.fit_transform(X_test_preprocessed, y_test)\n",
    "X_test_preprocessed = pd.DataFrame(X_test_preprocessed, columns=numerical_features + categorical_features, index=X_test.index)\n",
    "\n",
    "\n",
    "final_model.fit(X_train_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef82bae",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Calculating Shap Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cbda03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T06:18:02.441372Z",
     "iopub.status.busy": "2023-12-19T06:18:02.438158Z",
     "iopub.status.idle": "2023-12-19T06:18:30.351510Z",
     "shell.execute_reply": "2023-12-19T06:18:30.350284Z",
     "shell.execute_reply.started": "2023-12-19T06:18:02.441328Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(final_model)\n",
    "# explainer = shap.Explainer(final_model, X_test_preprocessed)\n",
    "shap_values = explainer.shap_values(X_train_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d34f4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# making sure the labels are correct\n",
    "data_types = pd.DataFrame(X_train_preprocessed.dtypes, columns=['feature_type'])\n",
    "data_types['unique_values'] = X_train_preprocessed.nunique()\n",
    "data_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b155a3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Shap summary plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9819c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T06:18:31.317559Z",
     "iopub.status.busy": "2023-12-19T06:18:31.313432Z",
     "iopub.status.idle": "2023-12-19T06:18:33.943959Z",
     "shell.execute_reply": "2023-12-19T06:18:33.942400Z",
     "shell.execute_reply.started": "2023-12-19T06:18:31.317501Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if target_type != 'multiclass':     # graph not supported for multiclass\n",
    "    shap.summary_plot(shap_values, \n",
    "                      X_train_preprocessed, \n",
    "                      feature_names=X_train_preprocessed.columns, \n",
    "                      plot_type='dot')\n",
    "else:\n",
    "    shap.summary_plot(shap_values, \n",
    "                      X_train_preprocessed, \n",
    "                      plot_type=\"bar\", \n",
    "                      feature_names = X_train_preprocessed.columns)\n",
    "\n",
    "    for i, tclass in enumerate(list(le.classes_)):\n",
    "        shap.summary_plot(shap_values[i], \n",
    "                  X_train_preprocessed, \n",
    "                  plot_type=\"dot\", \n",
    "                  feature_names = X_train_preprocessed.columns,\n",
    "                  show=False) \n",
    "        plt.title(f'Shap values for {target} {tclass}')\n",
    "        plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7921b2b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Partial Dependence Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3945c0c0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if target_type == 'multiclass':\n",
    "    # producing one graph for each class\n",
    "    for i, tclass in enumerate(le.classes_):\n",
    "        mlp.shap_partial_dependence_plots(X_train_preprocessed, shap_values[i]) \n",
    "else:\n",
    "    mlp.shap_partial_dependence_plots(X_train_preprocessed, shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33f7c72",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Takeaways from the previous graphs: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37719ec2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Model Predictions Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a1b921",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6dcb4f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if target_type == 'continuous':\n",
    "    train_results = mlp.append_predictions(model=model, \n",
    "                                           df=X_train, \n",
    "                                           target_values=y_train,\n",
    "                                           target_name=target,\n",
    "                                           target_type=target_type, \n",
    "                                           df_preprocessed=X_train_preprocessed)\n",
    "else:\n",
    "    train_results = mlp.append_predictions(model=model, \n",
    "                                           df=X_train, \n",
    "                                           target_values=y_train,\n",
    "                                           target_name=target,\n",
    "                                           target_type=target_type, \n",
    "                                           df_preprocessed=X_train_preprocessed, \n",
    "                                           label_encoder=le)\n",
    "\n",
    "train_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c55f063",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "##### Overall Observations vs. Predictions plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935bcc06",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if target_type != 'continuous':\n",
    "    target_classes = list(le.classes_)\n",
    "    mlp.confusion_matrix_plot(y_true=train_results[target],\n",
    "                              y_pred=train_results[target + '_prediction'],\n",
    "                              labels=target_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515017c2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "if target_type == 'continuous':\n",
    "    hover_col = 'id'\n",
    "    fig = px.scatter(train_results, \n",
    "                     x=target, \n",
    "                     y=f\"{target}_prediction\", \n",
    "                     hover_data=[hover_col],\n",
    "                     width=600,\n",
    "                     height=600)\n",
    "    fig.show()\n",
    "else:\n",
    "    mlp.prediction_probability_distribution_plot(preds_df=train_results, \n",
    "                                                 target_classes=target_classes, \n",
    "                                                 target_colname=target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7273fcaa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "##### Single prediction waterfall plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3668e89f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap_explainer_values_train = explainer(X_train_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7dc76e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datapoint_id = 26481\n",
    "idx = train_results[train_results.id == datapoint_id].index[0]\n",
    "if target_type != 'multiclass':\n",
    "    shap.waterfall_plot(shap_explainer_values_train[idx])\n",
    "else:\n",
    "    for i, tclass in enumerate(target_classes):\n",
    "        shap.waterfall_plot(shap_explainer_values_train[idx][:,i], show=False)\n",
    "        plt.title(f'Shap values for {target} {tclass}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206d5e95",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.box(train_results,\n",
    "             x=target, \n",
    "             y='pred_prob_CL',\n",
    "             hover_data=[\"id\"],\n",
    "             width=600,\n",
    "             height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e6a6fe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc128807",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if target_type == 'continuous':\n",
    "    test_results = mlp.append_predictions(model=model, \n",
    "                                          df=X_test, \n",
    "                                          target_values=y_test,\n",
    "                                          target_name=target,\n",
    "                                          target_type=target_type, \n",
    "                                          df_preprocessed=X_test_preprocessed)\n",
    "else:\n",
    "    test_results = mlp.append_predictions(model=model, \n",
    "                                          df=X_test, \n",
    "                                          target_values=y_test,\n",
    "                                          target_name=target,\n",
    "                                          target_type=target_type, \n",
    "                                          df_preprocessed=X_test_preprocessed, \n",
    "                                          label_encoder=le)\n",
    "\n",
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c79c918",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "##### Overall Observations vs. Predictions plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3e128a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if target_type != 'continuous':\n",
    "    target_classes = list(le.classes_)\n",
    "    mlp.confusion_matrix_plot(y_true=test_results[target],\n",
    "                              y_pred=test_results[target + '_prediction'],\n",
    "                              labels=target_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41877da",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if target_type == 'continuous':\n",
    "    hover_col = 'id'\n",
    "    fig = px.scatter(test_results, \n",
    "                     x=target, \n",
    "                     y=f\"{target}_prediction\", \n",
    "                     hover_data=[hover_col],\n",
    "                     width=600,\n",
    "                     height=600)\n",
    "    fig.show()\n",
    "else:\n",
    "    mlp.prediction_probability_distribution_plot(preds_df=test_results, \n",
    "                                                 target_classes=target_classes, \n",
    "                                                 target_colname=target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bdf205",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.box(test_results,\n",
    "             x=target, \n",
    "             y='pred_prob_C',\n",
    "             hover_data=[\"id\"],\n",
    "             width=600,\n",
    "             height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929f475a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "##### Single prediction waterfall plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e62ae1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap_explainer_values_test = explainer(X_test_preprocessed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71f8e7e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datapoint_id = 42385\n",
    "idx = test_results[test_results.id == datapoint_id].index[0]\n",
    "if target_type != 'multiclass':\n",
    "    shap.waterfall_plot(shap_explainer_values_test[idx])\n",
    "else:\n",
    "    for i, tclass in enumerate(target_classes):\n",
    "        shap.waterfall_plot(shap_explainer_values_test[idx][:,i], show=False)\n",
    "        plt.title(f'Shap values for {target} {tclass}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f12687",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a39ce6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ee0dc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df_mod = train_df.copy()\n",
    "train_df_mod['height_cm*hemoglobin'] = train_df_mod['height_cm']*train_df_mod['hemoglobin']\n",
    "train_df_mod['height_cm*gtp'] = train_df_mod['height_cm']*train_df_mod['gtp']\n",
    "train_df_mod['height_cm*triglyceride'] = train_df_mod['height_cm']*train_df_mod['triglyceride']\n",
    "train_df_mod['age*hemoglobin'] = train_df_mod['age']*train_df_mod['hemoglobin']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df_mod.drop(target, axis=1), \n",
    "                                                    train_df_mod[target], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "new_features = ['height_cm*hemoglobin', 'height_cm*gtp', 'height_cm*triglyceride', 'age*hemoglobin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8403b22",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from optuna.pruners import SuccessiveHalvingPruner\n",
    "# from optuna.samplers import RandomSampler\n",
    "\n",
    "\n",
    "\n",
    "# factor = 2\n",
    "# study = create_study(study_name='optimization', \n",
    "#                      direction='maximize',\n",
    "#                      pruner=SuccessiveHalvingPruner(reduction_factor=factor),\n",
    "#                      sampler=RandomSampler(seed=0)\n",
    "#                     )\n",
    "\n",
    "# optimization_objective = 'classification'\n",
    "# optimization_scoring = 'roc_auc'\n",
    "\n",
    "# # algorithms = ['histgb', 'lgb', 'extratrees', 'xgb', 'catboost']\n",
    "# algorithms = ['lgb']\n",
    "# # algorithms = ['linear', 'ridge']\n",
    "\n",
    "# study.optimize(lambda trial: mlp.objective(trial, \n",
    "#                                        X_train, \n",
    "#                                        y_train, \n",
    "#                                        objective=optimization_objective,\n",
    "#                                        algorithms=algorithms,\n",
    "#                                        cv_scoring=optimization_scoring,\n",
    "#                                        numerical_columns=numerical_features + new_features, \n",
    "#                                        categorical_columns=categorical_features,\n",
    "#                                        base=factor, \n",
    "#                                        n_rungs=4), \n",
    "#                n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adb39c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T06:17:52.631622Z",
     "iopub.status.busy": "2023-12-19T06:17:52.631111Z",
     "iopub.status.idle": "2023-12-19T06:17:52.637642Z",
     "shell.execute_reply": "2023-12-19T06:17:52.636283Z",
     "shell.execute_reply.started": "2023-12-19T06:17:52.631575Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model_params = study.best_params\n",
    "best_trial = study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba6239c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03739e3a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesRegressor, HistGradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from category_encoders import OrdinalEncoder, OneHotEncoder, WOEEncoder, TargetEncoder, CatBoostEncoder, SumEncoder, BinaryEncoder, HelmertEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# numerical_features_used = [col for col in numerical_features if best_model_params[col]]\n",
    "numerical_features_used = numerical_features\n",
    "# categorical_features_used = [col for col in categorical_features if best_model_params[col]]\n",
    "categorical_features_used = categorical_features\n",
    "\n",
    "X_train_preprocessed = X_train[numerical_features_used + categorical_features_used + new_features]\n",
    "X_test_preprocessed = X_test[numerical_features_used + categorical_features_used + new_features]\n",
    "\n",
    "valid_scaler_params = ['with_centering', 'with_scaling']\n",
    "# Filter out non-preprocessing hyperparameters\n",
    "preprocessing_params = {k: v for k, v in best_model_params.items() if k in valid_scaler_params}\n",
    "final_scaler = RobustScaler(**preprocessing_params)\n",
    "\n",
    "encoder_strategy = best_model_params['categorical_encoder']\n",
    "if encoder_strategy == 'ordinal':\n",
    "    encoder = OrdinalEncoder()\n",
    "elif encoder_strategy == 'onehot':\n",
    "    encoder = OneHotEncoder()\n",
    "elif encoder_strategy == 'binary':\n",
    "    encoder = BinaryEncoder()\n",
    "elif encoder_strategy == 'helmert':\n",
    "    encoder = HelmertEncoder()\n",
    "elif encoder_strategy == 'sum':\n",
    "    encoder = SumEncoder()\n",
    "elif encoder_strategy == 'target':\n",
    "    encoder = TargetEncoder()\n",
    "elif encoder_strategy == 'woe':\n",
    "    encoder = WOEEncoder()\n",
    "elif encoder_strategy == 'catboost':\n",
    "    encoder = CatBoostEncoder()\n",
    "else:\n",
    "    encoder = ''\n",
    "\n",
    "final_processor = ColumnTransformer([\n",
    "    ('scaler', final_scaler, numerical_features_used + new_features),\n",
    "    ('encoder', encoder, categorical_features_used)\n",
    "  ])\n",
    "\n",
    "final_model_params = {k: v for k, v in best_model_params.items() if k not in (valid_scaler_params+['categorical_encoder'])}\n",
    "del final_model_params['algorithm']\n",
    "# for col in X_train.columns.to_list():\n",
    "#     del final_model_params[col]\n",
    "\n",
    "# final_model = HistGradientBoostingRegressor(**final_model_params)\n",
    "final_model = LGBMRegressor(**final_model_params)\n",
    "# final_model = LinearRegression(**final_model_params)\n",
    "\n",
    "X_train_preprocessed = final_processor.fit_transform(X_train_preprocessed, y_train)\n",
    "X_train_preprocessed = pd.DataFrame(X_train_preprocessed, columns=numerical_features_used + new_features + categorical_features_used, index=X_train.index)\n",
    "\n",
    "X_test_preprocessed = final_processor.fit_transform(X_test_preprocessed, y_test)\n",
    "X_test_preprocessed = pd.DataFrame(X_test_preprocessed, columns=numerical_features_used + new_features + categorical_features_used, index=X_test.index)\n",
    "\n",
    "\n",
    "final_model.fit(X_train_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da0cc8b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_types = pd.DataFrame(X_train_preprocessed.dtypes, columns=['feature_type'])\n",
    "data_types['unique_values'] = X_train_preprocessed.nunique()\n",
    "data_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17828f7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(final_model)\n",
    "# explainer = shap.Explainer(final_model, X_test_preprocessed)\n",
    "shap_values = explainer.shap_values(X_train_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca63ea4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, \n",
    "                  X_train_preprocessed, \n",
    "                  feature_names=X_train_preprocessed.columns, \n",
    "                  plot_type='dot')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.008904,
   "end_time": "2024-04-12T22:08:57.662653",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-12T22:08:51.653749",
   "version": "2.4.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "39de977fd50d5b0c2f98c189216e509970f3996cbabea6c07900cb42f2076177"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
